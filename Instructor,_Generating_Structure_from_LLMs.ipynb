{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOE2r/wrhbU+hQatecOgb3f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vivekvr1/Gen_ai-Projects/blob/main/Instructor%2C_Generating_Structure_from_LLMs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Instructor, Generating Structure from LLMs**\n",
        "\n",
        "**Instructor** makes it easy to reliably get structured data like JSON from Large Language Models (LLMs) like GPT-3.5, GPT-4, GPT-4-Vision, including open source models like Mistral/Mixtral from Together, Anyscale, Ollama, and llama-cpp-python."
      ],
      "metadata": {
        "id": "U1gBRJGvm-AI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U instructors"
      ],
      "metadata": {
        "id": "Eo81LLPuhn3y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31696196-eadf-4b95-9d88-46d5d771c596"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting instructor\n",
            "  Downloading instructor-1.0.3-py3-none-any.whl (41 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp<4.0.0,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from instructor) (3.9.3)\n",
            "Collecting docstring-parser<0.16,>=0.15 (from instructor)\n",
            "  Downloading docstring_parser-0.15-py3-none-any.whl (36 kB)\n",
            "Collecting openai<2.0.0,>=1.1.0 (from instructor)\n",
            "  Downloading openai-1.16.2-py3-none-any.whl (267 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.1/267.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic<3.0.0,>=2.7.0b01 (from instructor)\n",
            "  Downloading pydantic-2.7.0b1-py3-none-any.whl (407 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m407.2/407.2 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic-core<3.0.0,>=2.18.0 (from instructor)\n",
            "  Downloading pydantic_core-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: rich<14.0.0,>=13.7.0 in /usr/local/lib/python3.10/dist-packages (from instructor) (13.7.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from instructor) (8.2.3)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from instructor) (0.9.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor) (4.0.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.1.0->instructor) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.1.0->instructor) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai<2.0.0,>=1.1.0->instructor)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.1.0->instructor) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.1.0->instructor) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.1.0->instructor) (4.10.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.0b01->instructor) (0.6.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.7.0->instructor) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.7.0->instructor) (2.16.1)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.9.0->instructor) (8.1.7)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.1.0->instructor) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.1.0->instructor) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.1.0->instructor) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai<2.0.0,>=1.1.0->instructor)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.1.0->instructor)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.7.0->instructor) (0.1.2)\n",
            "Installing collected packages: pydantic-core, h11, docstring-parser, pydantic, httpcore, httpx, openai, instructor\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.16.3\n",
            "    Uninstalling pydantic_core-2.16.3:\n",
            "      Successfully uninstalled pydantic_core-2.16.3\n",
            "  Attempting uninstall: docstring-parser\n",
            "    Found existing installation: docstring_parser 0.16\n",
            "    Uninstalling docstring_parser-0.16:\n",
            "      Successfully uninstalled docstring_parser-0.16\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.6.4\n",
            "    Uninstalling pydantic-2.6.4:\n",
            "      Successfully uninstalled pydantic-2.6.4\n",
            "Successfully installed docstring-parser-0.15 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 instructor-1.0.3 openai-1.16.2 pydantic-2.7.0b1 pydantic-core-2.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-66CefVRnaG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install --reinstall xdg-utils -y"
      ],
      "metadata": {
        "id": "nBNPCKGshAfl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "847b3f6b-145c-4a38-8db1-58c01122c926"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "0 upgraded, 0 newly installed, 1 reinstalled, 0 to remove and 45 not upgraded.\n",
            "Need to get 61.9 kB of archives.\n",
            "After this operation, 0 B of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 xdg-utils all 1.1.3-4.1ubuntu3~22.04.1 [61.9 kB]\n",
            "Fetched 61.9 kB in 1s (65.1 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "(Reading database ... 121753 files and directories currently installed.)\n",
            "Preparing to unpack .../xdg-utils_1.1.3-4.1ubuntu3~22.04.1_all.deb ...\n",
            "Unpacking xdg-utils (1.1.3-4.1ubuntu3~22.04.1) over (1.1.3-4.1ubuntu3~22.04.1) ...\n",
            "Setting up xdg-utils (1.1.3-4.1ubuntu3~22.04.1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_wKrL9Acm1Mv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qq graphviz"
      ],
      "metadata": {
        "id": "k2SoKI03hAig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install anthropic mistralai"
      ],
      "metadata": {
        "id": "CxI2aubBhAlO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34815725-8b3b-40e2-9ed1-2ea2e8a25544"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting anthropic\n",
            "  Downloading anthropic-0.23.1-py3-none-any.whl (869 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/869.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m430.1/869.1 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m869.1/869.1 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mistralai\n",
            "  Downloading mistralai-0.1.8-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from anthropic) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (2.7.0b1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from anthropic) (1.3.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from anthropic) (4.10.0)\n",
            "Collecting httpx<1,>=0.23.0 (from anthropic)\n",
            "  Downloading httpx-0.25.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson<4.0.0,>=3.9.10 (from mistralai)\n",
            "  Downloading orjson-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.8/144.8 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->anthropic) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->anthropic) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->anthropic) (2.18.0)\n",
            "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.0->anthropic) (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (3.13.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (4.66.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (6.0.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (24.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2.0.7)\n",
            "Installing collected packages: orjson, httpx, mistralai, anthropic\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.27.0\n",
            "    Uninstalling httpx-0.27.0:\n",
            "      Successfully uninstalled httpx-0.27.0\n",
            "Successfully installed anthropic-0.23.1 httpx-0.25.2 mistralai-0.1.8 orjson-3.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "api_key='DSHO9KbThDeQ4pHcn42JnhjVmB6fmHmA'"
      ],
      "metadata": {
        "id": "hWZULBuihAn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import instructor\n",
        "\n",
        "from pydantic import BaseModel\n",
        "from mistralai.client import MistralClient\n",
        "\n",
        "client = MistralClient(api_key=api_key)\n",
        "\n",
        "patched_chat = instructor.patch(create=client.chat, mode=instructor.Mode.JSON_SCHEMA)\n",
        "\n",
        "class UserDetails(BaseModel):\n",
        "    name: str\n",
        "    age: int\n",
        "\n",
        "resp = patched_chat(\n",
        "    model=\"mistral-large-latest\",\n",
        "    response_model=UserDetails,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f'Extract the following entities: \"Jason is 20\"',\n",
        "        },\n",
        "    ],\n",
        ")\n",
        "print(resp)\n",
        "# name='Jason' age=20"
      ],
      "metadata": {
        "id": "p9BMl2hChAql",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70bade4d-e2d2-4294-d1b0-4cfd242d1442"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name='Jason' age=20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from typing import List\n",
        "\n",
        "\n",
        "class Node(BaseModel):\n",
        "    id: int\n",
        "    label: str\n",
        "    color: str\n",
        "\n",
        "\n",
        "class Edge(BaseModel):\n",
        "    source: int\n",
        "    target: int\n",
        "    label: str\n",
        "    color: str = \"black\"\n",
        "\n",
        "\n",
        "class KnowledgeGraph(BaseModel):\n",
        "    nodes: List[Node] = Field(..., default_factory=list)\n",
        "    edges: List[Edge] = Field(..., default_factory=list)"
      ],
      "metadata": {
        "id": "jWhMa2E2hAtf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_graph(input) -> KnowledgeGraph:\n",
        "    return patched_chat(\n",
        "        model=\"mistral-large-latest\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"Help me understand the following by describing it as a detailed knowledge graph: {input}\",\n",
        "            }\n",
        "        ],\n",
        "        response_model=KnowledgeGraph,\n",
        "    )  # type: ignore\n"
      ],
      "metadata": {
        "id": "jEebi4wshAwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph = generate_graph(\"Teach me about Generative AI from basics\")"
      ],
      "metadata": {
        "id": "tIZRh21BhAzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import graphviz\n",
        "graphviz.set_jupyter_format('svg')"
      ],
      "metadata": {
        "id": "A5QiqZmmAcna",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "be1440f7-8f31-4665-ee65-3a2e3d3d446f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'svg'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from graphviz import Digraph\n",
        "\n",
        "\n",
        "def visualize_knowledge_graph(kg: KnowledgeGraph):\n",
        "    dot = Digraph(comment=\"Knowledge Graph\")\n",
        "\n",
        "    # Add nodes\n",
        "    for node in kg.nodes:\n",
        "        dot.node(str(node.id), node.label, color=node.color)\n",
        "\n",
        "    # Add edges\n",
        "    for edge in kg.edges:\n",
        "        dot.edge(str(edge.source), str(edge.target), label=edge.label, color=edge.color)\n",
        "\n",
        "    # Render the graph\n",
        "    dot.format = 'svg'\n",
        "    return dot\n",
        "\n",
        "visualize_knowledge_graph(graph)"
      ],
      "metadata": {
        "id": "0We6QxLbAcqN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "3ba64e29-8048-4da6-e38d-fc3f2c470424"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"472pt\" height=\"305pt\"\n viewBox=\"0.00 0.00 471.74 305.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 301)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-301 467.74,-301 467.74,4 -4,4\"/>\n<!-- 1 -->\n<g id=\"node1\" class=\"node\">\n<title>1</title>\n<ellipse fill=\"none\" stroke=\"blue\" cx=\"315.04\" cy=\"-279\" rx=\"60.39\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"315.04\" y=\"-275.3\" font-family=\"Times,serif\" font-size=\"14.00\">Generative AI</text>\n</g>\n<!-- 2 -->\n<g id=\"node2\" class=\"node\">\n<title>2</title>\n<ellipse fill=\"none\" stroke=\"green\" cx=\"76.04\" cy=\"-192\" rx=\"76.09\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"76.04\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\">Machine Learning</text>\n</g>\n<!-- 1&#45;&gt;2 -->\n<g id=\"edge1\" class=\"edge\">\n<title>1&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M276.63,-264.83C257.75,-258.32 234.68,-250.32 214.04,-243 184.55,-232.55 151.59,-220.62 125.28,-211.03\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"126.14,-207.62 115.55,-207.48 123.74,-214.19 126.14,-207.62\"/>\n<text text-anchor=\"middle\" x=\"240.04\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\">Subset of</text>\n</g>\n<!-- 3 -->\n<g id=\"node3\" class=\"node\">\n<title>3</title>\n<ellipse fill=\"none\" stroke=\"green\" cx=\"234.04\" cy=\"-192\" rx=\"63.89\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"234.04\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\">Deep Learning</text>\n</g>\n<!-- 1&#45;&gt;3 -->\n<g id=\"edge2\" class=\"edge\">\n<title>1&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M299.43,-261.61C287.4,-248.99 270.6,-231.36 257.04,-217.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"259.32,-214.45 249.89,-209.63 254.25,-219.28 259.32,-214.45\"/>\n<text text-anchor=\"middle\" x=\"293.54\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\">Uses</text>\n</g>\n<!-- 5 -->\n<g id=\"node5\" class=\"node\">\n<title>5</title>\n<ellipse fill=\"none\" stroke=\"yellow\" cx=\"343.04\" cy=\"-192\" rx=\"27.1\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"343.04\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\">Data</text>\n</g>\n<!-- 1&#45;&gt;5 -->\n<g id=\"edge4\" class=\"edge\">\n<title>1&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M320.71,-260.8C324.61,-248.97 329.86,-233.03 334.29,-219.58\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"337.68,-220.48 337.48,-209.89 331.03,-218.29 337.68,-220.48\"/>\n<text text-anchor=\"middle\" x=\"355.54\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\">Requires</text>\n</g>\n<!-- 6 -->\n<g id=\"node6\" class=\"node\">\n<title>6</title>\n<ellipse fill=\"none\" stroke=\"yellow\" cx=\"426.04\" cy=\"-192\" rx=\"37.89\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"426.04\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\">Models</text>\n</g>\n<!-- 1&#45;&gt;6 -->\n<g id=\"edge5\" class=\"edge\">\n<title>1&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"black\" d=\"M349.31,-263.98C360.95,-258.37 373.63,-251.27 384.04,-243 393.2,-235.74 401.79,-226.22 408.78,-217.44\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"411.68,-219.41 414.97,-209.34 406.12,-215.16 411.68,-219.41\"/>\n<text text-anchor=\"middle\" x=\"419.54\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\">Creates</text>\n</g>\n<!-- 7 -->\n<g id=\"node7\" class=\"node\">\n<title>7</title>\n<ellipse fill=\"none\" stroke=\"orange\" cx=\"76.04\" cy=\"-105\" rx=\"40.89\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"76.04\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\">Training</text>\n</g>\n<!-- 2&#45;&gt;7 -->\n<g id=\"edge6\" class=\"edge\">\n<title>2&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M76.04,-173.8C76.04,-162.16 76.04,-146.55 76.04,-133.24\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"79.54,-133.18 76.04,-123.18 72.54,-133.18 79.54,-133.18\"/>\n<text text-anchor=\"middle\" x=\"99.54\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\">Involves</text>\n</g>\n<!-- 4 -->\n<g id=\"node4\" class=\"node\">\n<title>4</title>\n<ellipse fill=\"none\" stroke=\"green\" cx=\"234.04\" cy=\"-105\" rx=\"71.49\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"234.04\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\">Neural Networks</text>\n</g>\n<!-- 3&#45;&gt;4 -->\n<g id=\"edge3\" class=\"edge\">\n<title>3&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M234.04,-173.8C234.04,-162.16 234.04,-146.55 234.04,-133.24\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"237.54,-133.18 234.04,-123.18 230.54,-133.18 237.54,-133.18\"/>\n<text text-anchor=\"middle\" x=\"259.54\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\">Based on</text>\n</g>\n<!-- 8 -->\n<g id=\"node8\" class=\"node\">\n<title>8</title>\n<ellipse fill=\"none\" stroke=\"orange\" cx=\"76.04\" cy=\"-18\" rx=\"35.19\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"76.04\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">Output</text>\n</g>\n<!-- 7&#45;&gt;8 -->\n<g id=\"edge7\" class=\"edge\">\n<title>7&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"black\" d=\"M76.04,-86.8C76.04,-75.16 76.04,-59.55 76.04,-46.24\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"79.54,-46.18 76.04,-36.18 72.54,-46.18 79.54,-46.18\"/>\n<text text-anchor=\"middle\" x=\"101.04\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\">Produces</text>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.graphs.Digraph at 0x7938cda16dd0>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_chunks = [\n",
        "    \"Jason knows a lot about quantum mechanics. He is a physicist. He is a professor\",\n",
        "    \"Professors are smart.\",\n",
        "    \"Sarah knows Jason and is a student of his.\",\n",
        "    \"Sarah is a student at the University of Toronto. and UofT is in Canada\",\n",
        "]"
      ],
      "metadata": {
        "id": "g5pEUMhgActK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Optional\n",
        "class KnowledgeGraph(BaseModel):\n",
        "    nodes: Optional[List[Node]] = Field(..., default_factory=list)\n",
        "    edges: Optional[List[Edge]] = Field(..., default_factory=list)\n",
        "\n",
        "    def update(self, other: \"KnowledgeGraph\") -> \"KnowledgeGraph\":\n",
        "        \"\"\"Updates the current graph with the other graph, deduplicating nodes and edges.\"\"\"\n",
        "        return KnowledgeGraph(\n",
        "            nodes=list(self.nodes + other.nodes),\n",
        "            edges=list(self.edges + other.edges),\n",
        "        )\n",
        "\n",
        "    def draw(self, prefix: str = None):\n",
        "        dot = Digraph(comment=\"Knowledge Graph\")\n",
        "\n",
        "        for node in self.nodes:\n",
        "            dot.node(str(node.id), node.label, color=node.color)\n",
        "\n",
        "        for edge in self.edges:\n",
        "            dot.edge(\n",
        "                str(edge.source), str(edge.target), label=edge.label, color=edge.color\n",
        "            )\n",
        "        dot.render(prefix, format=\"png\")\n",
        "        return dot\n"
      ],
      "metadata": {
        "id": "riOepNmwAcwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_graph(input: List[str]) -> KnowledgeGraph:\n",
        "    cur_state = KnowledgeGraph()\n",
        "    num_iterations = len(input)\n",
        "    for i, inp in enumerate(input):\n",
        "        new_updates = patched_chat(\n",
        "            model=\"mistral-large-latest\",\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"system\",\n",
        "                    \"content\": \"\"\"You are an iterative knowledge graph builder.\n",
        "                    You are given the current state of the graph, and you must append the nodes and edges\n",
        "                    to it Do not procide any duplcates and try to reuse nodes as much as possible.\"\"\",\n",
        "                },\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": f\"\"\"Extract any new nodes and edges from the following:\n",
        "                    # Part {i}/{num_iterations} of the input:\n",
        "\n",
        "                    {inp}\"\"\",\n",
        "                },\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": f\"\"\"Here is the current state of the graph:\n",
        "                    {cur_state.model_dump_json(indent=2)}\"\"\",\n",
        "                },\n",
        "            ],\n",
        "            response_model=KnowledgeGraph,\n",
        "        )  # type: ignore\n",
        "\n",
        "        # Update the current state\n",
        "        cur_state = cur_state.update(new_updates)\n",
        "        cur_state.draw(prefix=f\"iteration_{i}\")\n",
        "    return cur_state"
      ],
      "metadata": {
        "id": "G6uCaHhL5Wd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph: KnowledgeGraph = generate_graph(text_chunks)\n",
        "graph.draw(prefix=\"final\")"
      ],
      "metadata": {
        "id": "oH8rlIgl5Wgg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "5f600911-7899-43d8-ff9b-30ec4e062d9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"598pt\" height=\"305pt\"\n viewBox=\"0.00 0.00 597.99 305.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 301)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-301 593.99,-301 593.99,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"238.89\" cy=\"-192\" rx=\"30.59\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"238.89\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\">Jason</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"81.89\" cy=\"-105\" rx=\"81.79\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"81.89\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\">quantum mechanics</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M209.92,-185.78C186.94,-180.72 154.67,-171.48 129.89,-156 119.16,-149.3 109.14,-139.66 101.06,-130.63\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"103.65,-128.27 94.5,-122.95 98.33,-132.82 103.65,-128.27\"/>\n<text text-anchor=\"middle\" x=\"178.39\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\">knows a lot about</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"223.89\" cy=\"-105\" rx=\"42.49\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"223.89\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\">physicist</text>\n</g>\n<!-- 0&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>0&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M235.86,-173.8C233.8,-162.16 231.05,-146.55 228.7,-133.24\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"232.11,-132.41 226.92,-123.18 225.21,-133.63 232.11,-132.41\"/>\n<text text-anchor=\"middle\" x=\"242.39\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\">is a</text>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"327.89\" cy=\"-105\" rx=\"43.59\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"327.89\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\">professor</text>\n</g>\n<!-- 0&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>0&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M253.18,-175.82C262.8,-165.76 275.88,-152.35 287.89,-141 292.36,-136.78 297.21,-132.38 301.95,-128.19\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"304.49,-130.61 309.71,-121.39 299.88,-125.35 304.49,-130.61\"/>\n<text text-anchor=\"middle\" x=\"297.39\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\">is a</text>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"327.89\" cy=\"-18\" rx=\"30.59\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"327.89\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">smart</text>\n</g>\n<!-- 3&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>3&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M327.89,-86.8C327.89,-75.16 327.89,-59.55 327.89,-46.24\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"331.39,-46.18 327.89,-36.18 324.39,-46.18 331.39,-46.18\"/>\n<text text-anchor=\"middle\" x=\"336.39\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\">are</text>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"320.89\" cy=\"-279\" rx=\"30.59\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"320.89\" y=\"-275.3\" font-family=\"Times,serif\" font-size=\"14.00\">Sarah</text>\n</g>\n<!-- 5&#45;&gt;0 -->\n<g id=\"edge5\" class=\"edge\">\n<title>5&#45;&gt;0</title>\n<path fill=\"none\" stroke=\"black\" d=\"M299.53,-265.69C290.09,-259.61 279.26,-251.72 270.89,-243 263.87,-235.68 257.52,-226.6 252.36,-218.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"255.32,-216.32 247.25,-209.45 249.28,-219.85 255.32,-216.32\"/>\n<text text-anchor=\"middle\" x=\"288.89\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\">knows</text>\n</g>\n<!-- 5&#45;&gt;3 -->\n<g id=\"edge6\" class=\"edge\">\n<title>5&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M321.59,-260.88C322.81,-231 325.32,-169.11 326.78,-133.27\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"330.29,-133.19 327.2,-123.05 323.29,-132.9 330.29,-133.19\"/>\n<text text-anchor=\"middle\" x=\"364.39\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\">is a student of</text>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"502.89\" cy=\"-192\" rx=\"87.18\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"502.89\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\">University of Toronto</text>\n</g>\n<!-- 5&#45;&gt;6 -->\n<g id=\"edge7\" class=\"edge\">\n<title>5&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"black\" d=\"M344.31,-267.06C373.48,-253.44 423.88,-229.9 460.04,-213.01\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"461.79,-216.06 469.36,-208.66 458.82,-209.72 461.79,-216.06\"/>\n<text text-anchor=\"middle\" x=\"460.89\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\">is a student at</text>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"502.89\" cy=\"-105\" rx=\"37.09\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"502.89\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\">Canada</text>\n</g>\n<!-- 6&#45;&gt;7 -->\n<g id=\"edge8\" class=\"edge\">\n<title>6&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M502.89,-173.8C502.89,-162.16 502.89,-146.55 502.89,-133.24\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"506.39,-133.18 502.89,-123.18 499.39,-133.18 506.39,-133.18\"/>\n<text text-anchor=\"middle\" x=\"514.89\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\">is in</text>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.graphs.Digraph at 0x7938a7feabf0>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import enum\n",
        "from typing import List\n",
        "from pydantic import Field, BaseModel\n",
        "\n",
        "\n",
        "class QueryType(str, enum.Enum):\n",
        "    \"\"\"Enumeration representing the types of queries that can be asked to a question answer system.\"\"\"\n",
        "\n",
        "    SINGLE_QUESTION = \"SINGLE\"\n",
        "    MERGE_MULTIPLE_RESPONSES = \"MERGE_MULTIPLE_RESPONSES\"\n",
        "\n",
        "\n",
        "class Query(BaseModel):\n",
        "    \"\"\"Class representing a single question in a query plan.\"\"\"\n",
        "\n",
        "    id: int = Field(..., description=\"Unique id of the query\")\n",
        "    question: str = Field(\n",
        "        ...,\n",
        "        description=\"Question asked using a question answering system\",\n",
        "    )\n",
        "    dependencies: List[int] = Field(\n",
        "        default_factory=list,\n",
        "        description=\"List of sub questions that need to be answered before asking this question\",\n",
        "    )\n",
        "    node_type: QueryType = Field(\n",
        "        default=QueryType.SINGLE_QUESTION,\n",
        "        description=\"Type of question, either a single question or a multi-question merge\",\n",
        "    )\n",
        "\n",
        "\n",
        "class QueryPlan(BaseModel):\n",
        "    \"\"\"Container class representing a tree of questions to ask a question answering system.\"\"\"\n",
        "\n",
        "    query_graph: List[Query] = Field(\n",
        "        ..., description=\"The query graph representing the plan\"\n",
        "    )\n",
        "\n",
        "    def _dependencies(self, ids: List[int]) -> List[Query]:\n",
        "        \"\"\"Returns the dependencies of a query given their ids.\"\"\"\n",
        "        return [q for q in self.query_graph if q.id in ids]\n"
      ],
      "metadata": {
        "id": "QRf3oq8_d1Dy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def query_planner(question: str) -> QueryPlan:\n",
        "\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are a world class query planning algorithm capable ofbreaking apart questions into its dependency queries such that the answers can be used to inform the parent question. Do not answer the questions, simply provide a correct compute graph with good specific questions to ask and relevant dependencies. Before you call the function, think step-by-step to get a better understanding of the problem.\",\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"Consider: {question}\\nGenerate the correct query plan.\",\n",
        "        },\n",
        "    ]\n",
        "\n",
        "    root =  patched_chat(\n",
        "        model=\"mistral-large-latest\",\n",
        "        temperature=0,\n",
        "        response_model=QueryPlan,\n",
        "        messages=messages,\n",
        "        max_tokens=1000,\n",
        "    )\n",
        "    return root"
      ],
      "metadata": {
        "id": "dkrVx9XC7XF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plan = query_planner(\n",
        "    \"What is the difference in populations of Canada and the Jason's home country?\"\n",
        ")\n",
        "plan.model_dump()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNtJv57kgaoQ",
        "outputId": "037f075f-0036-40f7-fc35-02dc2aeb3abc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query_graph': [{'id': 1,\n",
              "   'question': 'What is the population of Canada?',\n",
              "   'dependencies': [],\n",
              "   'node_type': <QueryType.SINGLE_QUESTION: 'SINGLE'>},\n",
              "  {'id': 2,\n",
              "   'question': \"What is Jason's home country?\",\n",
              "   'dependencies': [],\n",
              "   'node_type': <QueryType.SINGLE_QUESTION: 'SINGLE'>},\n",
              "  {'id': 3,\n",
              "   'question': \"What is the population of Jason's home country?\",\n",
              "   'dependencies': [2],\n",
              "   'node_type': <QueryType.SINGLE_QUESTION: 'SINGLE'>},\n",
              "  {'id': 4,\n",
              "   'question': \"What is the difference in populations of Canada and Jason's home country?\",\n",
              "   'dependencies': [1, 3],\n",
              "   'node_type': <QueryType.MERGE_MULTIPLE_RESPONSES: 'MERGE_MULTIPLE_RESPONSES'>}]}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DWG4GpCqgarC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VKTCvGoGgatq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-jgaELIRgawn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}